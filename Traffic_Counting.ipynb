{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"models\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"models\", \"research\"))\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "from sort.sort import *\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"utils\"))\n",
    "from bb_polygon import *\n",
    "from img_utils import *\n",
    "from general_utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing object detection model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md):\n",
    "\n",
    "1. Right click on the Model name of the model you would like to use;\n",
    "2. Click on Copy link address to copy the download link of the model;\n",
    "3. Paste the link in a text editor of your choice. You should observe a link similar to download.tensorflow.org/models/object_detection/tf2/YYYYYYYY/XXXXXXXXX.tar.gz;\n",
    "4. Copy the XXXXXXXXX part of the link and use it to replace the value of the MODEL_NAME variable in the code shown below;\n",
    "5. Copy the YYYYYYYY part of the link and use it to replace the value of the MODEL_DATE variable in the code shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... Done! Took 21.71455979347229 seconds\n"
     ]
    }
   ],
   "source": [
    "MODEL_DATE = '20200711'\n",
    "MODEL_NAME = 'efficientdet_d3_coco17_tpu-32'\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)\n",
    "PATH_TO_CFG = PATH_TO_MODEL_DIR + \"/pipeline.config\"\n",
    "PATH_TO_CKPT = PATH_TO_MODEL_DIR + \"/checkpoint\"\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading COCO labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "PATH_TO_LABELS = download_labels(LABEL_FILENAME)\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading videos frames and ROI + MOI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discover 2 videos in ./data/videos\n"
     ]
    }
   ],
   "source": [
    "input_dir = './data/videos'\n",
    "output_dir= './data/frames' \n",
    "info_dir = './data/zones-movement_paths'\n",
    "video_output_dir = './data/videos_with_boundingbox'\n",
    "\n",
    "video_paths = get_videos(input_dir)\n",
    "print(\"Discover {} videos in {}\".format(len(video_paths), input_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection from video frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_object_dectection(video_path, frame_output_dir, zone_info_dir, \n",
    "                                         video_output_dir, output_to_video = False,\n",
    "                                         from_frame = 0, to_frame = None, time_stride = 1):   \n",
    "    extracted_frames = extract_frames_from_video(video_path, frame_output_dir)\n",
    "    roi, mois = extract_video_info(video_path, zone_info_dir)\n",
    "    \n",
    "    img = cv2.imread(extracted_frames[0])\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    if output_to_video:\n",
    "        output_file = os.path.join(video_output_dir, os.path.splitext(os.path.basename(video_path))[0] + '.mp4')\n",
    "        out = cv2.VideoWriter(output_file,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    frames_to_look = range(min(from_frame, len(extracted_frames)), \n",
    "                           min(to_frame, len(extracted_frames)) if to_frame is not None else len(extracted_frames), \n",
    "                           time_stride)    \n",
    "    for frame_id in tqdm(frames_to_look):    \n",
    "        frame = extracted_frames[frame_id]\n",
    "        \n",
    "        # Get object detection bounding boxes\n",
    "        frame_img, detections = object_detect_image(frame, detect_fn) \n",
    "        \n",
    "        if output_to_video:\n",
    "            # draw ROI and bounding boxes onto frame\n",
    "            image_np_with_detections = draw_roi_on_image(frame_img,roi)\n",
    "        \n",
    "            image_np_with_detections = draw_boxes(image_np_with_detections, detections['detection_boxes'], \n",
    "                                                  [category_index[i+1]['name'] for i in detections['detection_classes']], detections['detection_scores'],\n",
    "                                                 max_boxes=100, min_score=0.3)\n",
    "            out.write(image_np_with_detections[:, :, ::-1])\n",
    "    \n",
    "    if output_to_video:\n",
    "        out.release()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done! Took {} seconds for {} frames in video {}'.format(elapsed_time, len(frames_to_look), video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:55<00:00,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 175.44084000587463 seconds for 50 frames in video ./data/videos\\cam_01.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "video_object_dectection(video_paths[0], output_dir, info_dir, video_output_dir, True, 0, 50, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection and Tracking from video frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_object_dectection_and_tracking(video_path, frame_output_dir, zone_info_dir, \n",
    "                                         video_output_dir, output_to_video = False,\n",
    "                                         from_frame = 0, to_frame = None, time_stride = 1):   \n",
    "    tracker_1, tracker_2, tracker_3, tracker_4 = Sort(), Sort(), Sort(), Sort()\n",
    "    track_dict = {}\n",
    "\n",
    "    extracted_frames = extract_frames_from_video(video_path, frame_output_dir)\n",
    "    roi, mois = extract_video_info(video_path, zone_info_dir)\n",
    "    \n",
    "    img = cv2.imread(extracted_frames[0])\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    if output_to_video:\n",
    "        output_file = os.path.join(video_output_dir, os.path.splitext(os.path.basename(video_path))[0] + '_with_tracking.mp4')\n",
    "        out = cv2.VideoWriter(output_file,cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    frames_to_look = range(min(from_frame, len(extracted_frames)), \n",
    "                           min(to_frame, len(extracted_frames)) if to_frame is not None else len(extracted_frames), \n",
    "                           time_stride)    \n",
    "    for frame_id in tqdm(frames_to_look):    \n",
    "        frame = extracted_frames[frame_id]\n",
    "        \n",
    "        # Get object detection bounding boxes\n",
    "        frame_img, detections = object_detect_image(frame, detect_fn) \n",
    "        \n",
    "        if output_to_video:\n",
    "            # draw ROI and bounding boxes onto frame\n",
    "            image_np_with_detections = draw_roi_on_image(frame_img,roi)\n",
    "        \n",
    "        # update SORT trackers \n",
    "        min_score = 0.2\n",
    "        dets_1 = change_detections_to_image_coordinates(detections, roi, width, height, [1,2,4], min_score=min_score)\n",
    "        if len(dets_1) > 0:\n",
    "            trackers_1 = tracker_1.update(dets_1)\n",
    "            update_track_dict(track_dict, trackers_1, frame_id, 1)\n",
    "            if output_to_video:\n",
    "                image_np_with_detections = draw_boxes_and_lines(image_np_with_detections, trackers_1, track_dict, 'Type 1')\n",
    "            \n",
    "        dets_2 = change_detections_to_image_coordinates(detections, roi, width, height, [3], min_score=min_score)\n",
    "        if len(dets_2) > 0:\n",
    "            trackers_2 = tracker_1.update(dets_2)\n",
    "            update_track_dict(track_dict, trackers_2, frame_id, 2)\n",
    "            if output_to_video:\n",
    "                image_np_with_detections = draw_boxes_and_lines(image_np_with_detections, trackers_2, track_dict, 'Type 2')\n",
    "        \n",
    "        dets_3 = change_detections_to_image_coordinates(detections, roi, width, height, [6], min_score=min_score)\n",
    "        if len(dets_3) > 0:\n",
    "            trackers_3 = tracker_1.update(dets_3)\n",
    "            update_track_dict(track_dict, trackers_3, frame_id, 3)\n",
    "            if output_to_video:\n",
    "                image_np_with_detections = draw_boxes_and_lines(image_np_with_detections, trackers_3, track_dict, 'Type 3')\n",
    "        \n",
    "        dets_4 = change_detections_to_image_coordinates(detections, roi, width, height, [8], min_score=min_score)\n",
    "        if len(dets_4) > 0:\n",
    "            trackers_4 = tracker_1.update(dets_4)\n",
    "            update_track_dict(track_dict, trackers_4, frame_id, 4)\n",
    "            if output_to_video:\n",
    "                image_np_with_detections = draw_boxes_and_lines(image_np_with_detections, trackers_4, track_dict, 'Type 4')\n",
    "        \n",
    "        if output_to_video:\n",
    "            out.write(image_np_with_detections[:, :, ::-1])\n",
    "    \n",
    "    if output_to_video:\n",
    "        out.release()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done! Took {} seconds for {} frames in video {}'.format(elapsed_time, len(frames_to_look), video_path))\n",
    "    \n",
    "    return track_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [01:49<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 109.18736505508423 seconds for 50 frames in video ./data/videos\\cam_01.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tracks = video_object_dectection_and_tracking(video_paths[0], output_dir, info_dir, video_output_dir, True, 0, 50, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: count vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
